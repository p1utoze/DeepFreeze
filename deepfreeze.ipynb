{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9944803,"sourceType":"datasetVersion","datasetId":6114878}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install --upgrade torchvision -q\n!pip install segmentation_models_pytorch lightly prefetch_generator torchinfo -q\n!pip install -U albumentations -q ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\nimport torch\nimport time\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.cuda.amp import GradScaler, autocast\nimport torchvision.transforms as transforms\nfrom torchvision.transforms import v2\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom transformers import ViTModel, ViTConfig\nfrom segmentation_models_pytorch import Unet, encoders\nfrom torchvision.io import read_image, ImageReadMode\nimport matplotlib.pyplot as plt\nimport glob\nimport numpy as np\nfrom scipy import ndimage\nfrom scipy.signal import medfilt2d, wiener\nimport random\nimport cv2\nfrom lightly.models.modules import BarlowTwinsProjectionHead\nfrom lightly.loss import barlow_twins_loss\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torchinfo import summary\nfrom prefetch_generator import BackgroundGenerator\nfrom rich import print\nfrom torchmetrics import MetricCollection\nfrom torchmetrics.image import PeakSignalNoiseRatio, SpatialCorrelationCoefficient, StructuralSimilarityIndexMeasure, RootMeanSquaredErrorUsingSlidingWindow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.seed(1)\ntorch.manual_seed(1)\ntorch.cuda.manual_seed(1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATA_ROOT = Path(\"/kaggle/input/cresis-radar-depth-sounder/\")\nseason_name = DATA_ROOT / \"2023_Antarctica_BaslerMKB\"\nimg_list = glob.glob(\"**/*.jpg\",recursive=True, root_dir=season_name)\nimg_list = [season_name / f for f in img_list]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport random \ndef load_image_torchvision(filepath):\n        return read_image(filepath, mode=ImageReadMode.GRAY)\n\ndef need_permute(image):\n    if len(image.shape) == 3:\n            image = image.permute(1, 2, 0)\n    return image\n    \ndef show_image(image_path, enable_augmented=False, transforms=None):\n    if not enable_augmented:\n        image = load_image_torchvision(samp_path)\n        image = need_permute(image)\n        fig, ax = plt.subplots()\n        ax.imshow(image_tensor, cmap=\"gray\")\n        plt.axis('off')\n        plt.show()\n        \n    image = cv2.imread(image_path)\n    aug_image = transforms(image=image)[\"image\"]\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    aug_image, image = need_permute(aug_image), need_permute(torch.from_numpy(image))\n    fig, ax = plt.subplots(1, 2, figsize=(10, 8))\n    ax[0].imshow(image, cmap=\"gray\")\n    ax[0].axis(\"off\")\n    ax[0].set_title(\"Raw Input Image\")\n    \n    ax[1].imshow(aug_image, cmap=\"gray\")\n    ax[1].axis(\"off\")\n    ax[1].set_title(\"Albumentations Augmented Image\")\n    \n    plt.tight_layout()\n    plt.show()\n    \ndef create_augmentation_pipe():\n    return A.Compose([\n    # A.Sharpen(),\n    A.RandomBrightnessContrast(\n        brightness_limit=0.05,contrast_limit=0.05\n    ),\n    A.GaussianBlur((5, 5), p=1),\n    A.Emboss(alpha=(0.5, 0.9), strength=(0.4, 0.8)),\n    A.RandomSnow(\n        brightness_coeff=0.9,\n        snow_point_range=(0.1, 0.3),\n    ),\n    # A.CLAHE(),\n    A.ToGray(num_output_channels=1, always_apply=True),\n    A.Normalize(),\n    A.LongestMaxSize(512, interpolation=cv2.INTER_NEAREST),\n    A.ToFloat(),\n    ToTensorV2(),\n])    \n    \n# Example usage\ntransforms = create_augmentation_pipe()\nsamp_path = random.choice(img_list)\nshow_image(samp_path, enable_augmented=True, transforms=transforms)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the image\nimage_path = random.choice(img_list)\nimage = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n\ntransforms = A.Compose([\n    # A.Emboss(p=1),\n    A.RandomBrightnessContrast(0.05, 0.05, p=1),\n    A.Posterize(8, p=1),\n    A.GaussianBlur((5, 5), p=1)\n])\n# Step 1: Apply Gaussian blur\n# blurred = cv2.GaussianBlur(image, (5, 5), 0)\nblurred = transforms(image=image)[\"image\"]\n\n\n# Step 2: Apply multi-scale edge detection\nedges = cv2.Canny(blurred, 25, 50)\nedges2 = cv2.Canny(blurred, 50, 75)\nedges3 = cv2.Canny(blurred, 75, 100)\nedges4 = cv2.Canny(blurred, 125, 150)\n# edges_multi_scale = cv2.Canny(blurred, 100, 150)\ncombined_edges1 = cv2.addWeighted(edges, 1, edges2, 1, 0)\ncombined_edges2 = cv2.addWeighted(edges3, 1, edges4, 1, 0)\ncombined_edges = cv2.addWeighted(combined_edges1, 0.5, combined_edges2, 0.5, 0)\n\n\n# Step 3: Use morphological operations to clean up\nkernel = np.ones((3, 3), np.uint8)\ndilated = cv2.dilate(combined_edges, kernel, iterations=1)\neroded = cv2.erode(dilated, kernel, iterations=1)\n\n# Display the result\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.title('Original Image')\nplt.imshow(image, cmap='gray')\nplt.subplot(1, 2, 2)\nplt.title('Processed Image with Multi-Scale Edges')\nplt.imshow(eroded, cmap='terrain', filternorm=True)\nplt.show()\n\n# Save the processed image\ncv2.imwrite('processed_multi_scale_edges.png', eroded)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class NoiseFilters:\n    \"\"\"\n    Collection of noise filtering techniques for ice echograms\n    \"\"\"\n    @staticmethod\n    def median_filter(image, kernel_size=3):\n        \"\"\"Apply median filter to reduce salt-and-pepper noise\"\"\"\n        return medfilt2d(image, kernel_size=kernel_size)\n    \n    @staticmethod\n    def wiener_filter(image, kernel_size=3):\n        \"\"\"Apply Wiener filter to reduce gaussian noise\"\"\"\n        return wiener(image, (kernel_size, kernel_size))\n    \n    @staticmethod\n    def bilateral_filter(image, d=9, sigma_color=75, sigma_space=75):\n        \"\"\"Apply bilateral filter to reduce noise while preserving edges\"\"\"\n        return cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n    \n    @staticmethod\n    def adaptive_histogram_equalization(image, clip_limit=2.0, tile_size=8):\n        \"\"\"Apply CLAHE to improve contrast\"\"\"\n        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(tile_size, tile_size))\n        return clahe.apply(np.uint8(image * 255)) / 255.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EchogramAugmentor:\n    \"\"\"\n    Specialized augmentation techniques for ice sheet echograms\n    \"\"\"\n    def __init__(self, p=0.5):\n        self.p = p\n        self.noise_filters = NoiseFilters()\n        \n    def add_gaussian_noise(self, image, mean=0, std=0.01):\n        \"\"\"Add Gaussian noise to simulate sensor noise\"\"\"\n        noise = np.random.normal(mean, std, image.shape)\n        noisy_image = image + noise\n        return np.clip(noisy_image, 0, 1)\n    \n    def add_speckle_noise(self, image, intensity=0.1):\n        \"\"\"Add multiplicative noise typical in radar systems\"\"\"\n        noise = np.random.normal(1, intensity, image.shape)\n        noisy_image = image * noise\n        return np.clip(noisy_image, 0, 1)\n    \n    def simulate_signal_attenuation(self, image, alpha=0.1):\n        \"\"\"Simulate depth-dependent signal attenuation\"\"\"\n        height = image.shape[0]\n        attenuation = np.exp(-alpha * np.arange(height)[:, np.newaxis])\n        return image * attenuation\n    \n    def simulate_surface_multiple(self, image, intensity=0.3):\n        \"\"\"Simulate surface multiple reflections\"\"\"\n        height = image.shape[0]\n        surface_multiple = np.roll(image, height//2, axis=0) * intensity\n        return np.clip(image + surface_multiple, 0, 1)\n    \n    def random_intensity_shift(self, image, max_shift=0.1):\n        \"\"\"Apply random intensity shifts\"\"\"\n        shift = np.random.uniform(-max_shift, max_shift)\n        return np.clip(image + shift, 0, 1)\n    \n    def random_contrast(self, image, min_factor=0.8, max_factor=1.2):\n        \"\"\"Apply random contrast adjustment\"\"\"\n        factor = np.random.uniform(min_factor, max_factor)\n        mean = image.mean()\n        return np.clip((image - mean) * factor + mean, 0, 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class IceEchogramDataset(Dataset):\n    def __init__(self, image_paths, augment=True, filter_noise=True, transforms=None):\n        \"\"\"\n        Enhanced dataset class with augmentation and filtering\n        Args:\n            image_paths (list): List of paths to echogram images\n            augment (bool): Whether to apply augmentation\n            filter_noise (bool): Whether to apply noise filtering\n        \"\"\"\n        self.image_paths = image_paths\n        self.augment = augment\n        self.filter_noise = filter_noise\n        # self.augmentor = EchogramAugmentor(p=0.5)\n        # self.noise_filters = NoiseFilters()\n        self.transforms = transforms\n        \n    def preprocess_image(self, image):\n        \"\"\"Apply noise filtering pipeline\"\"\"\n        if self.filter_noise:\n            # Apply series of filters\n            image = self.noise_filters.median_filter(image)\n            image = self.noise_filters.bilateral_filter(image)\n            image = self.noise_filters.adaptive_histogram_equalization(image)\n        return image\n    \n    def augment_image(self, image):\n        \"\"\"Apply augmentation pipeline\"\"\"\n        if not self.augment:\n            return image\n            \n        # Randomly apply augmentations\n        if random.random() < self.augmentor.p:\n            image = self.augmentor.add_gaussian_noise(image)\n        if random.random() < self.augmentor.p:\n            image = self.augmentor.add_speckle_noise(image)\n        if random.random() < self.augmentor.p:\n            image = self.augmentor.simulate_signal_attenuation(image)\n        if random.random() < self.augmentor.p:\n            image = self.augmentor.simulate_surface_multiple(image)\n        if random.random() < self.augmentor.p:\n            image = self.augmentor.random_intensity_shift(image)\n        if random.random() < self.augmentor.p:\n            image = self.augmentor.random_contrast(image)\n            \n        return image\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        # Load image\n        image = cv2.imread(self.image_paths[idx])\n\n        if self.transforms:\n            image = self.transforms(image=image)[\"image\"]\n        \n        # # Apply noise filtering\n        # image = self.preprocess_image(image)\n        \n        # # Apply augmentation\n        # image = self.augment_image(image)\n        \n        # # Convert to tensor\n        # image = torch.from_numpy(image).float()\n        \n        # Add channel dimension if needed\n        if image.dim() == 2:\n            image = image.unsqueeze(0)\n            \n        return image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAINER_CONFIG = dict(\n    TRAIN_RATIO = 0.8,\n    BATCH_SIZE = 8,\n    NUM_WORKERS = 4,\n    EPOCHS = 10,\n    LEARNING_RATE = 1e-2,\n    WEIGHT_DECAY = 0.0 # Increase if overfitting\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transforms = A.Compose([\n    # A.Sharpen(),\n    A.RandomBrightnessContrast(\n        brightness_limit=0.05,contrast_limit=0.05\n    ),\n    A.GaussianBlur((5, 5), p=1),\n    A.ToGray(num_output_channels=1, always_apply=True),\n    A.Normalize(),\n    A.Resize(512, 512, interpolation=cv2.INTER_NEAREST),\n    A.ToFloat(),\n    ToTensorV2(),\n])\n\ndataset = IceEchogramDataset(\n        image_paths=img_list,\n        augment=False,\n        filter_noise=False,\n        transforms=transforms\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_size = len(dataset)\ntrain_size = int(TRAINER_CONFIG['TRAIN_RATIO'] * total_size)\nval_size = total_size - train_size\n\ntrain_dataset, val_dataset = torch.utils.data.random_split(\n    dataset, [train_size, val_size]\n)\n\n# Create dataloaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=TRAINER_CONFIG[\"BATCH_SIZE\"],\n    shuffle=True,\n    num_workers=TRAINER_CONFIG[\"NUM_WORKERS\"],\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=TRAINER_CONFIG[\"BATCH_SIZE\"],\n    shuffle=False,\n    num_workers=TRAINER_CONFIG[\"NUM_WORKERS\"],\n    pin_memory=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class IceLayerTracer(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super(IceLayerTracer, self).__init__()\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n        )\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.Sigmoid(),\n        )\n        \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"net = IceLayerTracer()\nsummary(net, input_data=next(iter(train_loader)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, config, metrics: list = None):\n        self.model = model\n        self.config = config\n\n        # Define the optimizer and loss function\n        self.optimizer = optim.Adam(model.parameters(), lr=config[\"LEARNING_RATE\"])\n        self.criterion = nn.MSELoss()\n        # self.proj_head = BarlowTwinsProjectionHead(256, 256, 256)\n        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=100, eta_min=1e-5)\n        self.epochs = self.config[\"EPOCHS\"]\n        metrics = MetricCollection(metrics, compute_on_cpu=True)\n        self.train_metrics = metrics.clone(prefix=\"train_\")\n        self.val_metrics = metrics.clone(prefix=\"val_\")\n        \n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        if self.device:\n            self.model.to(self.device)\n            self.train_metrics = self.train_metrics.to(self.device)\n            self.val_metrics = self.val_metrics.to(self.device)\n\n    def train(self, dataloader, epoch):\n        self.model.train()\n        pbar = tqdm(BackgroundGenerator(dataloader), total=len(dataloader))\n        start_time = time.time()\n        total_loss = 0\n        for batch in pbar:\n            if self.device:\n                batch = batch.to(self.device)\n            \n            prepare_time = start_time-time.time()\n            \n            # Initialise optimizer\n            self.optimizer.zero_grad()\n            \n            # Forward pass\n            out = self.model(batch)\n\n            loss = self.criterion(out, batch)\n            # loss = barlow_twins_loss(\n            #     self.proj_head(self.model.encoder(batch)), \n            #     self.proj_head(self.model.encoder(out)), \n            #     lambda_=0.0051\n            # )\n            # total_loss += loss.item()\n\n            # Calculate train metrics\n            _ = self.train_metrics(out, batch)\n            \n            # Backward pass and optimization\n            loss.backward()\n            self.optimizer.step()\n\n            self.scheduler.step()\n            process_time = start_time-time.time()-prepare_time\n            pbar.set_description(\"Compute efficiency: {:.2f}, epoch: {}/{}:\".format(\n                    process_time/(process_time+prepare_time), epoch, self.epochs))\n            start_time = time.time()\n        return total_loss / len(dataloader)\n\n    def validate(self, dataloader):\n        self.model.eval()\n        # Validation and logging\n        pbar = tqdm(BackgroundGenerator(dataloader), total=len(dataloader))\n        total_loss = 0\n        with torch.no_grad():\n            for batch in pbar:\n                if self.device:\n                    batch = batch.to(self.device)\n                val_out = self.model(batch)\n                # val_loss = barlow_twins_loss(proj_head(self.model.encoder(batch)), proj_head(self.model.encoder(val_out)), lambda_=0.0051)\n                # total_loss += val_loss.item()\n\n                # Calculate train metrics\n                _ = self.val_metrics.update(val_out, batch)\n\n        return total_loss\n\n    def fit(self, dataloaders: [DataLoader, DataLoader]):\n        train_loader, val_loader = dataloaders\n        train_loss, val_loss, best_val_loss = 0, float('inf'), float('inf')\n        for epoch in range(self.epochs):\n            _ = self.train(train_loader, epoch)\n            \n            # print(f'Training Loss: {train_loss:.4f}')\n            train_metrics_out = self.train_metrics.compute()\n            train_loss = train_metrics_out[\"train_rmse_sw\"]\n            \n            if epoch % 2 == 1:\n                _ = self.validate(val_loader)\n                val_metrics_out = self.val_metrics.compute()\n                val_loss = val_metrics_out[\"val_rmse_sw\"]\n                wandb.log(val_metrics_out)\n                \n            print(f'Training Loss {train_loss:.4f}    |    Validation Loss: {val_loss:.4f}')\n            print(f'Training SSIM {train_loss:.4f}    |    Validation SSIM: {val_loss:.4f}')\n            \n            \n            # print(train_metrics_out.keys())\n            wandb.log(train_metrics_out)\n            \n            # Save checkpoint if best model\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                self.save_checkpoint(epoch, val_loss)\n                \n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": train_loss , \n                \"val_loss\": val_loss,\n                \"best_val_loss\": best_val_loss \n            })\n            print(f\"[bold cyan]{'-' * 100}\")\n            self.train_metrics.reset()\n            self.val_metrics.reset()\n\n    def save_checkpoint(self, epoch, val_loss):\n        \"\"\"Save model checkpoint\"\"\"\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'val_loss': val_loss,\n        }, f'checkpoint_epoch_{epoch}.pt')\n        # run.log_model(path=\"/kaggle/working/\", name=\"<name>\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.init(\n    project=\"Deep Freeze\",\n    config={\n        \"dataset\": \"CReSIS-RDS\",\n        \"architecture\": \"AutoEncoder\",\n        **TRAINER_CONFIG\n    }\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics = {\n    \"rmse_sw\": RootMeanSquaredErrorUsingSlidingWindow(),\n    \"psnr\": PeakSignalNoiseRatio(), \n    \"scc\": SpatialCorrelationCoefficient(), \n    \"ssim\": StructuralSimilarityIndexMeasure()\n}\n\n# net = IceLayerTracer()\ntrainer = Trainer(net, TRAINER_CONFIG, metrics)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.fit([train_loader, val_loader])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom transformers import ViTModel, ViTConfig\nfrom segmentation_models_pytorch import Unet, encoders\n\nclass IceLayerAnalysisModel(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.config = config\n        \n        # Encoder Backbone\n        self.encoder = self._build_encoder_backbone()\n        \n        # Feature Pyramid Network\n        self.fpn = self._build_feature_pyramid()\n        \n        # Layer Tracking Branch\n        self.layer_tracking = self._build_layer_tracking_branch()\n        \n        # Segmentation Branch\n        self.segmentation = self._build_segmentation_branch()\n        \n        # Feature Detection Branch\n        self.feature_detection = self._build_feature_detection_branch()\n        \n        # Initialize weights\n        self.initialize_weights()\n    \n    def _build_encoder_backbone(self):\n        # Use ResNet50 as the backbone encoder\n        encoder = encoders.get_encoder(\n            name=\"resnet50\",\n            in_channels=1,\n            depth=5,\n            weights=ResNet50_Weights.IMAGENET1K_V2\n        )\n        return encoder\n    \n    def _build_feature_pyramid(self):\n        # Construct Feature Pyramid Network\n        return nn.ModuleDict({\n            \"p1\": nn.Sequential(\n                nn.Conv2d(encoder.out_channels[0], 256, 1),\n                nn.BatchNorm2d(256),\n                nn.ReLU(inplace=True)\n            ),\n            \"p2\": nn.Sequential(\n                nn.Conv2d(encoder.out_channels[1], 256, 1),\n                nn.BatchNorm2d(256),\n                nn.ReLU(inplace=True)\n            ),\n            \"p3\": nn.Sequential(\n                nn.Conv2d(encoder.out_channels[2], 256, 1),\n                nn.BatchNorm2d(256),\n                nn.ReLU(inplace=True)\n            ),\n            \"p4\": nn.Sequential(\n                nn.Conv2d(encoder.out_channels[3], 256, 1),\n                nn.BatchNorm2d(256),\n                nn.ReLU(inplace=True)\n            )\n        })\n    \n    def _build_layer_tracking_branch(self):\n        # Use Transformer-based sequence modeling for layer tracking\n        transformer_config = ViTConfig(\n            num_layers=6,\n            num_heads=8,\n            hidden_size=256\n        )\n        return ViTModel(transformer_config)\n    \n    def _build_segmentation_branch(self):\n        # Use Unet with ASPP module for segmentation\n        return Unet(\n            encoder_name=\"resnet50\",\n            encoder_weights=\"imagenet\",\n            in_channels=1,\n            classes=self.config.num_layer_classes\n        )\n    \n    def _build_feature_detection_branch(self):\n        # Use attention-based feature detection\n        return nn.Sequential(\n            nn.Conv2d(256, 128, 3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(128, self.config.num_feature_classes)\n        )\n    \n    def initialize_weights(self):\n        # Initialize weights for custom layers\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        # Encoder backbone\n        encoder_features = self.encoder(x)\n        \n        # Feature Pyramid Network\n        p1 = self.fpn[\"p1\"](encoder_features[0])\n        p2 = self.fpn[\"p2\"](encoder_features[1])\n        p3 = self.fpn[\"p3\"](encoder_features[2])\n        p4 = self.fpn[\"p4\"](encoder_features[3])\n        \n        # Layer Tracking Branch\n        layer_features = torch.cat([p1, p2, p3, p4], dim=1)\n        layer_coords = self.layer_tracking(layer_features)[0]\n        \n        # Segmentation Branch\n        segmentation_masks = self.segmentation(x)\n        \n        # Feature Detection Branch\n        feature_maps = torch.cat([p1, p2, p3, p4], dim=1)\n        feature_scores = self.feature_detection(feature_maps)\n        \n        return {\n            \"layers\": layer_coords,\n            \"segmentation\": segmentation_masks,\n            \"features\": feature_scores\n        }","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class IceLayerTrainer:\n    def __init__(self, model, config):\n        self.model = model\n        self.config = config\n        self.device = config.DEVICE\n        self.scaler = GradScaler()  # For mixed precision training\n        \n        # Initialize optimizers\n        self.optimizer = optim.AdamW(\n            model.parameters(),\n            lr=config.LEARNING_RATE,\n            weight_decay=config.WEIGHT_DECAY\n        )\n        \n        # Learning rate scheduler\n        self.scheduler = CosineAnnealingWarmRestarts(\n            self.optimizer,\n            T_0=config.T_0,\n            T_mult=config.T_MULT,\n            eta_min=config.MIN_LR\n        )\n\n        \n    def train_epoch(self, dataloader, epoch):\n        self.model.train()\n        total_loss = 0\n        pbar = tqdm(enumerate(BackgroundGenerator(dataloader)), total=len(dataloader))\n        for batch_idx, data in enumerate(dataloader):\n            data = data.to(self.device)\n            # targets = {k: v.to(self.device) for k, v in targets.items()}\n            \n            # Mixed precision training\n            with autocast():\n                # Forward pass\n                outputs = self.model(data)\n                \n                # Calculate losses\n                layer_loss = self.compute_layer_loss(\n                    outputs['layers'], \n                    targets['layers']\n                )\n                seg_loss = self.compute_seg_loss(\n                    outputs['segmentation'], \n                    targets['segmentation']\n                )\n                feature_loss = self.compute_feature_loss(\n                    outputs['features'], \n                    targets['features']\n                )\n                \n                # Weighted sum of losses\n                loss = (\n                    self.layer_weight * layer_loss +\n                    self.seg_weight * seg_loss +\n                    self.feature_weight * feature_loss\n                )\n            \n            # Backward pass with gradient scaling\n            self.optimizer.zero_grad()\n            self.scaler.scale(loss).backward()\n            self.scaler.step(self.optimizer)\n            self.scaler.update()\n            \n            total_loss += loss.item()\n            \n            # Progressive layer unfreezing\n            if epoch > self.config.unfreeze_epoch:\n                self._unfreeze_layers()\n                \n        # Update learning rate\n        self.scheduler.step()\n        \n        return total_loss / len(dataloader)\n    \n    def train(self, train_loader, val_loader, num_epochs):\n        \"\"\"Complete training loop with curriculum learning\"\"\"\n        best_val_loss = float('inf')\n        \n        for epoch in range(num_epochs):\n            # Update curriculum difficulty\n            if epoch in self.config.curriculum_milestones:\n                self._increase_difficulty()\n            \n            # Train epoch\n            train_loss = self.train_epoch(train_loader, epoch)\n            \n            # Validate\n            val_loss = self.validate(val_loader)\n            \n            # Save checkpoint if best model\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                self.save_checkpoint(epoch, val_loss)\n                \n    def _increase_difficulty(self):\n        \"\"\"Implement curriculum learning strategy\"\"\"\n        # Start with simple cases (clear layers, strong contrast)\n        # Gradually introduce more complex cases\n        self.train_dataset.increase_difficulty()\n        \n    def _unfreeze_layers(self):\n        \"\"\"Progressive unfreezing of layers\"\"\"\n        for name, param in self.model.named_parameters():\n            param.requires_grad = True\n            \n    def save_checkpoint(self, epoch, val_loss):\n        \"\"\"Save model checkpoint\"\"\"\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'val_loss': val_loss,\n        }, f'checkpoint_epoch_{epoch}.pt')","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null}]}